{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5738896e-b128-4724-ab55-b3fe9113743d",
   "metadata": {},
   "source": [
    "# Lab 3: A Conditional Generative Model for Images \n",
    "Welcome to lab 3! In the previous lab, we studied *unconditional* generation, for toy, two-dimensional data distributions. In this lab, we will study *conditional* generation on *images* from the MNIST dataset of handwritten digits. Each such MNIST image is not two dimensions but $32\\times 32 = 1024$ dimensions! The nature of our new, more challenging setting will require us to take special care:\n",
    "1. To tackle *conditional* generation, we will employ *classifier-free guidance* (CFG) (see Part 2.1).\n",
    "2. To parameterize our learned vector field for high-dimensional image-valued data, a simple MLP will not suffice. Instead, we will adopt the *U-Net* architecture (see part 2.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec94580-5913-432b-83ae-c86667867068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, List, Type, Tuple, Dict\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes._axes import Axes\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as D\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c02887-12f1-40c9-8384-31fde27bcf4e",
   "metadata": {},
   "source": [
    "### Part 0: Recycling Components from Previous Labs\n",
    "In this section, we'll re-import previous components from labs one and two. In doing so, we'll make some important updates. First, let's revisit our `Sampleable` class from labs one and two. Below, we have named it `OldSampleable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035a73b-67d9-421f-9c1f-eac9edf526ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OldSampleable(ABC):\n",
    "    \"\"\"\n",
    "    Distribution which can be sampled from\n",
    "    \"\"\"        \n",
    "    @abstractmethod\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - num_samples: the desired number of samples\n",
    "        Returns:\n",
    "            - samples: shape (batch_size, ...)\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5900b74-1960-44ed-b837-664d6daa1a96",
   "metadata": {},
   "source": [
    "As we will see shortly, a dataset like MNIST contains both images (in this case handwritten digits), as well as class labels (a value from 0-9 indicating). We will therefore generalize our notion of `Sampleable` to accommodate these labels as well. Whereas the old, `OldSampleable.sample` method returned only `samples: torch.Tensor`, we will now have it return both `samples: torch.Tensor` *and* `labels: Optional[torch.Tensor]`. In this way, we are formally realizing every such `Sampleable` instance as sampling from a *joint distribution* over data and labels. We implement our new `Sampleable` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd228f1b-f545-45ce-92b7-b12efc45acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampleable(ABC):\n",
    "    \"\"\"\n",
    "    Distribution which can be sampled from\n",
    "    \"\"\" \n",
    "    @abstractmethod\n",
    "    def sample(self, num_samples: int) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - num_samples: the desired number of samples\n",
    "        Returns:\n",
    "            - samples: shape (batch_size, ...)\n",
    "            - labels: shape (batch_size, label_dim)\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef363df-4446-4cc7-ad17-72c10a2a4aec",
   "metadata": {},
   "source": [
    "For certain distributions, such as a Gaussian, it doesn't really make sense to think about labels. For this reason we have made the labels return value Optional: a Gaussian can just return `None`. Below, we implement the class `IsotropicGaussian`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e1038-724b-41f4-82b5-3ecec43a1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsotropicGaussian(nn.Module, Sampleable):\n",
    "    \"\"\"\n",
    "    Sampleable wrapper around torch.randn\n",
    "    \"\"\"\n",
    "    def __init__(self, shape: List[int], std: float = 1.0):\n",
    "        \"\"\"\n",
    "        shape: shape of sampled data\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        self.std = std\n",
    "        self.dummy = nn.Buffer(torch.zeros(1)) # Will automatically be moved when self.to(...) is called...\n",
    "        \n",
    "    def sample(self, num_samples) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.std ** 2 * torch.randn(num_samples, *self.shape).to(self.dummy.device), None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227b4fc-b6c7-4575-ae7e-65ca78b7931a",
   "metadata": {},
   "source": [
    "Next, we make two updates in adding `ConditionalProbabilityPath` (and `GaussianConditionalProbabilityPath`):\n",
    "1. We adjust to handle the addition of labels to `Sampleable`. Recall earlier that our called our conditioning variable `z` with $z \\sim p_{\\text{data}}(z)$. Now, we sample both `z`, as well as a label `y`, with $(z,y) \\sim p_{\\text{data}}(z,y)$.\n",
    "2. We ensure that the logic is compatible with shapes of size `(batch_size, c, h, w)`, rather than `(batch_size, dim)`. While the latter was sufficient for 2D data of shape `(batch_size, 2)`, we will now be working with images which, when batched, have shape `(batch_size, c, h, w)`. Here `c`, `h`, and `w`, denote the number of channels, the height, and the width, respectively.\n",
    "3. To avoid any unfortunate broadcasting issues, we will maintain our time variable `t` in the shape `(batch_size, 1, 1, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f47f3-d25b-4100-8b51-0a7d32152dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalProbabilityPath(nn.Module, ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for conditional probability paths\n",
    "    \"\"\"\n",
    "    def __init__(self, p_simple: Sampleable, p_data: Sampleable):\n",
    "        super().__init__()\n",
    "        self.p_simple = p_simple\n",
    "        self.p_data = p_data\n",
    "\n",
    "    def sample_marginal_path(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the marginal distribution p_t(x) = p_t(x|z) p(z)\n",
    "        Args:\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - x: samples from p_t(x), (num_samples, c, h, w)\n",
    "        \"\"\"\n",
    "        num_samples = t.shape[0]\n",
    "        # Sample conditioning variable z ~ p(z)\n",
    "        z, _ = self.sample_conditioning_variable(num_samples) # (num_samples, c, h, w)\n",
    "        # Sample conditional probability path x ~ p_t(x|z)\n",
    "        x = self.sample_conditional_path(z, t) # (num_samples, c, h, w)\n",
    "        return x\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Samples the conditioning variable z and label y\n",
    "        Args:\n",
    "            - num_samples: the number of samples\n",
    "        Returns:\n",
    "            - z: (num_samples, c, h, w)\n",
    "            - y: (num_samples, label_dim)\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the conditional distribution p_t(x|z)\n",
    "        Args:\n",
    "            - z: conditioning variable (num_samples, c, h, w)\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - x: samples from p_t(x|z), (num_samples, c, h, w)\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional vector field u_t(x|z)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, c, h, w)\n",
    "            - z: conditioning variable (num_samples, c, h, w)\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - conditional_vector_field: conditional vector field (num_samples, c, h, w)\n",
    "        \"\"\" \n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional score of p_t(x|z)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, c, h, w)\n",
    "            - z: conditioning variable (num_samples, c, h, w)\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - conditional_score: conditional score (num_samples, c, h, w)\n",
    "        \"\"\" \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c477562-a3c4-4ba1-9e78-849eb97d4eb5",
   "metadata": {},
   "source": [
    "Finally, we add back in `GaussianConditionalProbabilityPath`, along with `LinearAlpha` and `LinearBeta`, defined similarly to the previous lab. Here, we must be careful to avoid irksome broadcasting issues: broadcasting e.g., `alpha(t)` of shape `(batch_size, 1)` together with `x` of shape `(batch_size, c, h, w)` will not work! We alleviate this issue by ensuring that `alpha(t)` and `beta(t)` are, similarly to `t` itself, also both of shape `(batch_size, 1, 1, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235eb52-9bf9-4fd7-8162-b12437322849",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alpha(ABC):\n",
    "    def __init__(self):\n",
    "        # Check alpha_t(0) = 0\n",
    "        assert torch.allclose(\n",
    "            self(torch.zeros(1,1)), torch.zeros(1,1)\n",
    "        )\n",
    "        # Check alpha_1 = 1\n",
    "        assert torch.allclose(\n",
    "            self(torch.ones(1,1)), torch.ones(1,1)\n",
    "        )\n",
    "        \n",
    "    @abstractmethod\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates alpha_t. Should satisfy: self(0.0) = 0.0, self(1.0) = 1.0.\n",
    "        Args:\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - alpha_t (num_samples, 1, 1, 1)\n",
    "        \"\"\" \n",
    "        pass\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates d/dt alpha_t.\n",
    "        Args:\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - d/dt alpha_t (num_samples, 1, 1, 1)\n",
    "        \"\"\" \n",
    "        t = t.unsqueeze(1)\n",
    "        dt = vmap(jacrev(self))(t)\n",
    "        return dt.view(-1, 1, 1, 1)\n",
    "    \n",
    "class Beta(ABC):\n",
    "    def __init__(self):\n",
    "        # Check beta_0 = 1\n",
    "        assert torch.allclose(\n",
    "            self(torch.zeros(1,1)), torch.ones(1,1)\n",
    "        )\n",
    "        # Check beta_1 = 0\n",
    "        assert torch.allclose(\n",
    "            self(torch.ones(1,1)), torch.zeros(1,1)\n",
    "        )\n",
    "        \n",
    "    @abstractmethod\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates alpha_t. Should satisfy: self(0.0) = 1.0, self(1.0) = 0.0.\n",
    "        Args:\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - beta_t (num_samples, 1, 1, 1)\n",
    "        \"\"\" \n",
    "        pass \n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates d/dt beta_t.\n",
    "        Args:\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - d/dt beta_t (num_samples, 1, 1, 1)\n",
    "        \"\"\" \n",
    "        t = t.unsqueeze(1)\n",
    "        dt = vmap(jacrev(self))(t)\n",
    "        return dt.view(-1, 1, 1, 1)\n",
    "\n",
    "class LinearAlpha(Alpha):\n",
    "    \"\"\"\n",
    "    Implements alpha_t = t\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - alpha_t (num_samples, 1, 1, 1)\n",
    "        \"\"\" \n",
    "        return t\n",
    "    \n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates d/dt alpha_t.\n",
    "        Args:\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - d/dt alpha_t (num_samples, 1, 1, 1)\n",
    "        \"\"\" \n",
    "        return torch.ones_like(t)\n",
    "        \n",
    "class LinearBeta(Beta):\n",
    "    \"\"\"\n",
    "    Implements beta_t = 1-t\n",
    "    \"\"\"\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - beta_t (num_samples, 1)\n",
    "        \"\"\" \n",
    "        return 1-t\n",
    "        \n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates d/dt alpha_t.\n",
    "        Args:\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - d/dt alpha_t (num_samples, 1, 1, 1)\n",
    "        \"\"\" \n",
    "        return - torch.ones_like(t)\n",
    "    \n",
    "class GaussianConditionalProbabilityPath(ConditionalProbabilityPath):\n",
    "    def __init__(self, p_data: Sampleable, p_simple_shape: List[int], alpha: Alpha, beta: Beta):\n",
    "        p_simple = IsotropicGaussian(shape = p_simple_shape, std = 1.0)\n",
    "        super().__init__(p_simple, p_data)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples the conditioning variable z and label y\n",
    "        Args:\n",
    "            - num_samples: the number of samples\n",
    "        Returns:\n",
    "            - z: (num_samples, c, h, w)\n",
    "            - y: (num_samples, label_dim)\n",
    "        \"\"\"\n",
    "        return self.p_data.sample(num_samples)\n",
    "    \n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the conditional distribution p_t(x|z)\n",
    "        Args:\n",
    "            - z: conditioning variable (num_samples, c, h, w)\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - x: samples from p_t(x|z), (num_samples, c, h, w)\n",
    "        \"\"\"\n",
    "        return self.alpha(t) * z + self.beta(t) * torch.randn_like(z)\n",
    "        \n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional vector field u_t(x|z)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, c, h, w)\n",
    "            - z: conditioning variable (num_samples, c, h, w)\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - conditional_vector_field: conditional vector field (num_samples, c, h, w)\n",
    "        \"\"\" \n",
    "        alpha_t = self.alpha(t) # (num_samples, 1, 1, 1)\n",
    "        beta_t = self.beta(t) # (num_samples, 1, 1, 1)\n",
    "        dt_alpha_t = self.alpha.dt(t) # (num_samples, 1, 1, 1)\n",
    "        dt_beta_t = self.beta.dt(t) # (num_samples, 1, 1, 1)\n",
    "\n",
    "        return (dt_alpha_t - dt_beta_t / beta_t * alpha_t) * z + dt_beta_t / beta_t * x\n",
    "\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional score of p_t(x|z)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, c, h, w)\n",
    "            - z: conditioning variable (num_samples, c, h, w)\n",
    "            - t: time (num_samples, 1, 1, 1)\n",
    "        Returns:\n",
    "            - conditional_score: conditional score (num_samples, c, h, w)\n",
    "        \"\"\" \n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        return (z * alpha_t - x) / beta_t ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e193c8-7ad3-431c-8c85-e5708668bb89",
   "metadata": {},
   "source": [
    "Now, let us accordingly update our `ODE`, `SDE`, and `Simulator` classes. This is pretty much a matter of \n",
    "1. Updating `t: (batch_size, 1)` to `t: (batch_size, 1, 1, 1)`, and `xt: (batch_size, dim)` to `(batch_size, c, h, w)`. For brevity, we will usually use `bs` as shorthand for `batch_size`.\n",
    "2. Adding support for an optional *conditioning* input `y: Optional[torch.Tensor]`. We will opt to more simply add a generic `**kwargs` to the signatures of the relevant methods (`drift_coefficient`, `diffusion_coefficient`, `step`, `simulate`, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a84df25-3802-406e-928c-bae5faab935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODE(ABC):\n",
    "    @abstractmethod\n",
    "    def drift_coefficient(self, xt: torch.Tensor, t: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the drift coefficient of the ODE.\n",
    "        Args:\n",
    "            - xt: state at time t, shape (bs, c, h, w)\n",
    "            - t: time, shape (bs, 1)\n",
    "        Returns:\n",
    "            - drift_coefficient: shape (bs, c, h, w)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class SDE(ABC):\n",
    "    @abstractmethod\n",
    "    def drift_coefficient(self, xt: torch.Tensor, t: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the drift coefficient of the ODE.\n",
    "        Args:\n",
    "            - xt: state at time t, shape (bs, c, h, w)\n",
    "            - t: time, shape (bs, 1, 1, 1)\n",
    "        Returns:\n",
    "            - drift_coefficient: shape (bs, c, h, w)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def diffusion_coefficient(self, xt: torch.Tensor, t: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the diffusion coefficient of the ODE.\n",
    "        Args:\n",
    "            - xt: state at time t, shape (bs, c, h, w)\n",
    "            - t: time, shape (bs, 1, 1, 1)\n",
    "        Returns:\n",
    "            - diffusion_coefficient: shape (bs, c, h, w)\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb58139-c64f-481b-8aa5-fb0f81353bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(ABC):\n",
    "    @abstractmethod\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, dt: torch.Tensor, **kwargs):\n",
    "        \"\"\"\n",
    "        Takes one simulation step\n",
    "        Args:\n",
    "            - xt: state at time t, shape (bs, c, h, w)\n",
    "            - t: time, shape (bs, 1, 1, 1)\n",
    "            - dt: time, shape (bs, 1, 1, 1)\n",
    "        Returns:\n",
    "            - nxt: state at time t + dt (bs, c, h, w)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def simulate(self, x: torch.Tensor, ts: torch.Tensor, **kwargs):\n",
    "        \"\"\"\n",
    "        Simulates using the discretization gives by ts\n",
    "        Args:\n",
    "            - x_init: initial state, shape (bs, c, h, w)\n",
    "            - ts: timesteps, shape (bs, nts, 1, 1, 1)\n",
    "        Returns:\n",
    "            - x_final: final state at time ts[-1], shape (bs, c, h, w)\n",
    "        \"\"\"\n",
    "        nts = ts.shape[1]\n",
    "        for t_idx in tqdm(range(nts - 1)):\n",
    "            t = ts[:, t_idx]\n",
    "            h = ts[:, t_idx + 1] - ts[:, t_idx]\n",
    "            x = self.step(x, t, h, **kwargs)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def simulate_with_trajectory(self, x: torch.Tensor, ts: torch.Tensor, **kwargs):\n",
    "        \"\"\"\n",
    "        Simulates using the discretization gives by ts\n",
    "        Args:\n",
    "            - x: initial state, shape (bs, c, h, w)\n",
    "            - ts: timesteps, shape (bs, nts, 1, 1, 1)\n",
    "        Returns:\n",
    "            - xs: trajectory of xts over ts, shape (batch_size, nts, c, h, w)\n",
    "        \"\"\"\n",
    "        xs = [x.clone()]\n",
    "        nts = ts.shape[1]\n",
    "        for t_idx in tqdm(range(nts - 1)):\n",
    "            t = ts[:,t_idx]\n",
    "            h = ts[:, t_idx + 1] - ts[:, t_idx]\n",
    "            x = self.step(x, t, h, **kwargs)\n",
    "            xs.append(x.clone())\n",
    "        return torch.stack(xs, dim=1)\n",
    "\n",
    "class EulerSimulator(Simulator):\n",
    "    def __init__(self, ode: ODE):\n",
    "        self.ode = ode\n",
    "        \n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: torch.Tensor, **kwargs):\n",
    "        return xt + self.ode.drift_coefficient(xt,t, **kwargs) * h\n",
    "\n",
    "class EulerMaruyamaSimulator(Simulator):\n",
    "    def __init__(self, sde: SDE):\n",
    "        self.sde = sde\n",
    "        \n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: torch.Tensor, **kwargs):\n",
    "        return xt + self.sde.drift_coefficient(xt,t, **kwargs) * h + self.sde.diffusion_coefficient(xt,t, **kwargs) * torch.sqrt(h) * torch.randn_like(xt)\n",
    "\n",
    "def record_every(num_timesteps: int, record_every: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the indices to record in the trajectory given a record_every parameter\n",
    "    \"\"\"\n",
    "    if record_every == 1:\n",
    "        return torch.arange(num_timesteps)\n",
    "    return torch.cat(\n",
    "        [\n",
    "            torch.arange(0, num_timesteps - 1, record_every),\n",
    "            torch.tensor([num_timesteps - 1]),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c79041e-f801-4a48-9dfd-e950dae209f4",
   "metadata": {},
   "source": [
    "Finally, let's add back in our definition of `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8d6fd-e5d8-4cd7-a3d9-2b2327ca1172",
   "metadata": {},
   "outputs": [],
   "source": [
    "MiB = 1024 ** 2\n",
    "\n",
    "def model_size_b(model: nn.Module) -> int:\n",
    "    \"\"\"\n",
    "    Returns model size in bytes. Based on https://discuss.pytorch.org/t/finding-model-size/130275/2\n",
    "    Args:\n",
    "    - model: self-explanatory\n",
    "    Returns:\n",
    "    - size: model size in bytes\n",
    "    \"\"\"\n",
    "    size = 0\n",
    "    for param in model.parameters():\n",
    "        size += param.nelement() * param.element_size()\n",
    "    for buf in model.buffers():\n",
    "        size += buf.nelement() * buf.element_size()\n",
    "    return size\n",
    "\n",
    "class Trainer(ABC):\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_train_loss(self, **kwargs) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "    def get_optimizer(self, lr: float):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def train(self, num_epochs: int, device: torch.device, lr: float = 1e-3, **kwargs) -> torch.Tensor:\n",
    "        # Report model size\n",
    "        size_b = model_size_b(self.model)\n",
    "        print(f'Training model with size: {size_b / MiB:.3f} MiB')\n",
    "        \n",
    "        # Start\n",
    "        self.model.to(device)\n",
    "        opt = self.get_optimizer(lr)\n",
    "        self.model.train()\n",
    "\n",
    "        # Train loop\n",
    "        pbar = tqdm(enumerate(range(num_epochs)))\n",
    "        for idx, epoch in pbar:\n",
    "            opt.zero_grad()\n",
    "            loss = self.get_train_loss(**kwargs)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            pbar.set_description(f'Epoch {idx}, loss: {loss.item():.3f}')\n",
    "\n",
    "        # Finish\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85821a69-c29b-4c4d-9910-17cc43e1dc39",
   "metadata": {},
   "source": [
    "# Part 1: Getting a Feel for MNIST\n",
    "In this section, we'll get a feel for MNIST. We'll then experiment with adding noise to MNIST with `ConditionalGaussianProbabilityPath`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200dc0b9-5ae1-4eab-9216-54c42bc7d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTSampler(nn.Module, Sampleable):\n",
    "    \"\"\"\n",
    "    Sampleable wrapper for the MNIST dataset\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dataset = datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize((32, 32)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ])\n",
    "        )\n",
    "        self.dummy = nn.Buffer(torch.zeros(1)) # Will automatically be moved when self.to(...) is called...\n",
    "\n",
    "    def sample(self, num_samples: int) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - num_samples: the desired number of samples\n",
    "        Returns:\n",
    "            - samples: shape (batch_size, c, h, w)\n",
    "            - labels: shape (batch_size, label_dim)\n",
    "        \"\"\"\n",
    "        if num_samples > len(self.dataset):\n",
    "            raise ValueError(f\"num_samples exceeds dataset size: {len(self.dataset)}\")\n",
    "        \n",
    "        indices = torch.randperm(len(self.dataset))[:num_samples]\n",
    "        samples, labels = zip(*[self.dataset[i] for i in indices])\n",
    "        samples = torch.stack(samples).to(self.dummy)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64).to(self.dummy.device)\n",
    "        return samples, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a57db-f1ce-4406-9ef6-8c3780e9540e",
   "metadata": {},
   "source": [
    "Now let's view some samples under the conditional probability path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a510332b-2807-4c46-8c68-362c34a86630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these!\n",
    "num_rows = 3\n",
    "num_cols = 3\n",
    "num_timesteps = 5\n",
    "\n",
    "# Initialize our sampler\n",
    "sampler = MNISTSampler().to(device)\n",
    "\n",
    "# Initialize probability path\n",
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data = MNISTSampler(),\n",
    "    p_simple_shape = [1, 32, 32],\n",
    "    alpha = LinearAlpha(),\n",
    "    beta = LinearBeta()\n",
    ").to(device)\n",
    "\n",
    "# Sample \n",
    "num_samples = num_rows * num_cols\n",
    "z, _ = path.p_data.sample(num_samples)\n",
    "z = z.view(-1, 1, 32, 32)\n",
    "\n",
    "# Setup plot\n",
    "fig, axes = plt.subplots(1, num_timesteps, figsize=(6 * num_cols * num_timesteps, 6 * num_rows))\n",
    "\n",
    "# Sample from conditional probability paths and graph\n",
    "ts = torch.linspace(0, 1, num_timesteps).to(device)\n",
    "for tidx, t in enumerate(ts):\n",
    "    tt = t.view(1,1,1,1).expand(num_samples, 1, 1, 1) # (num_samples, 1, 1, 1)\n",
    "    xt = path.sample_conditional_path(z, tt) # (num_samples, 1, 32, 32)\n",
    "    grid = make_grid(xt, nrow=num_cols, normalize=True, value_range=(-1,1))\n",
    "    axes[tidx].imshow(grid.permute(1, 2, 0).cpu(), cmap=\"gray\")\n",
    "    axes[tidx].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a574647-2c63-49f3-bd1f-5b4b495f497e",
   "metadata": {},
   "source": [
    "# Part 2: Classifier Free Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93551880-8440-4167-97d3-4e38ea5f6abc",
   "metadata": {},
   "source": [
    "### Part 2.1: Classifier Free Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d042ba3-3a53-496b-8153-d1e32dac52ce",
   "metadata": {},
   "source": [
    "**Guidance**: Whereas for unconditional generation, we simply wanted to generate *any* digit, we would now like to be able to specify, or *condition*, on the identity of the digit we would like to generate. That is, we would like to be able to say \"generate an image of the digit 8\", rather than just \"generate an image of a digit\". We will henceforth refer to the digit we would like to generate as $x \\in \\mathbb{R}^{1 \\times 32 \\times 32}$, and the conditioning variable (in this case, a label), as $y \\in \\{0, 1, \\dots, 9\\}$. If we imagine fixing our choice of $y$, and take our data distribution as $p_{\\text{simple}}(x|y)$, then we have recovered the unconditional generative problem, and we construct a generative model using e.g., a conditional flow matching objective via $$ \\mathcal{L}_{\\text{CFM}}(\\theta) = \\,\\,\\mathbb{E}_{z \\sim p_{\\text{data}}(z|y), x \\sim p_t(x|z)} \\lVert u_t^{\\theta}(x|y) - u_t^{\\text{ref}}(x|z,y)\\rVert^2.$$\n",
    "Since the label doesn't actually affect the conditional probability path, the above can be further simplified with $u_t^{\\text{ref}}(x|z,y) = u_t^{\\text{ref}}(x|z)$, which we have worked with already. We may now then allow $y$ to vary by simply taking our conditional flow matching expectation to be over $y$ as well (rather than fixing $y$), and explicitly conditioning our learned approximation on $u_t^{\\theta}(x|y)$ on the choice of $y$. We therefore obtain the the *guided* conditional flow matching objective $$\\mathcal{L}_{\\text{CFM}}(\\theta) = \\,\\,\\mathbb{E}_{z,y \\sim p_{\\text{data}}(z,y), x \\sim p_t(x|z)} \\lVert u_t^{\\theta}(x|y) - u_t^{\\text{ref}}(x|z,y)\\rVert^2.$$\n",
    "Note that $(z,y) \\sim p_{\\text{simple}}(z,y)$ is obtained in practice by sampling an image $z$, and a label $y$, from our labelled (MNIST) dataset. This is all well and good, and we would expect that our model might learn to condition on $y$ reasonably well. *But, for Gaussian conditional probability paths, we can do better*. We will do better using a technique called *classifier-free guidance*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dfb8be-778a-4c8b-964e-29253d5537ab",
   "metadata": {},
   "source": [
    "**Classifier-Free Guidance**: Recall from the lecture that for $(a_t, b_t) = \\left(\\frac{\\dot{\\alpha}_t}{\\beta_t}, -\\frac{\\dot{\\beta}_t \\beta_t \\alpha_t - \\dot{\\alpha}_t \\beta_t^2}{\\alpha_t}\\right)$, we have $$u_t(x|y) = a_tx + b_t\\nabla \\log p_t(x|y).$$\n",
    "This identity allows us to relate the *conditional marginal velocity* $u_t(x|y)$ to the *conditional score* $\\nabla \\log p_t(x|y)$. However, notice that $$\\nabla \\log p_t(x|y) = \\nabla \\log \\left(\\frac{p_t(x)p_t(y|x)}{p_t(y)}\\right) = \\nabla \\log p_t(x) + \\nabla \\log p_t(y|x),$$\n",
    "so that we may rewrite $$u_t(x|y) = a_tx + b_t(\\nabla \\log p_t(x) + \\nabla \\log p_t(y|x)) = u_t(x) + b_t \\nabla \\log p_t(y|x).$$\n",
    "An approximation of the term $\\nabla \\log p_t(y|x)$ could be considered as a sort of noisy classifier (and in fact this is the origin of *classifier guidance*, which we do not consider here). In practice, people have noticed that the conditioning seems to work better when we scale the contribution of this classifier term, yielding\n",
    "$$\\tilde{u}_t(x|y) = u_t(x) + w b_t \\nabla \\log p_t(y|x)$$\n",
    "where $w > 1$ is known as the *guidance scale*. We may again apply the equality $$\\nabla \\log p_t(x|y) = \\nabla \\log p_t(x) + \\nabla \\log p_t(y|x)$$ to obtain $$\\begin{align}\\tilde{u}_t(x|y) &= u_t(x) + w b_t \\nabla \\log p_t(y|x)\\\\\n",
    "&= u_t(x) + w b_t (\\nabla \\log p_t(x|y) - \\nabla \\log p_t(x))\\\\\n",
    "&= u_t(x) - (w a_tx + w b_t \\nabla \\log p_t(x)) + (w a_t x + w b_t \\nabla \\log p_t(x|y))\\\\\n",
    "&= (1-w) u_t(x) + w u_t(x|y) \\end{align}.$$\n",
    "The idea is thus to train both $u_t(x)$ as well as the conditional model $u_t(x|y)$, and then combine them *at inference time* to obtain $\\tilde{u}_t(x|y)$. Our recipe will thus be:\n",
    "1. Train $u_t^{\\theta} \\approx u_t(x)$ as well as the conditional model $u_t^{\\theta}(x|y) \\approx u_t(x|y)$ using conditional flow matching.\n",
    "2. At inference time, sample using $\\tilde{u}_t^{\\theta}(x|y)$.\n",
    "\n",
    "\"But wait!\", you say, \"why must we train two models?\". Indeed, we can instead treat $u_t(x)$ as $u_t(x|y)$, where $y=\\varnothing$ denotes *the absence of conditioning*. We may thus augment our label set with a new, additional $\\varnothing$ label, so that $y \\in \\{0,1,\\dots, 9, \\varnothing\\}$. This technique is known as **classifier-free guidance** (CFG). We thus arrive at\n",
    "$$\\boxed{\\tilde{u}_t(x|y) = (1-w) u_t(x|\\varnothing) + w u_t(x|y)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8728902-21ce-4b00-b4f1-bb3573542206",
   "metadata": {},
   "source": [
    "**Training and CFG**: We must now amend our conditional flow matching objective to account for the possibility of $y = \\varnothing$. Of course, when we sample $(z,y)$ from MNIST, we will never obtain $y = \\varnothing$, so we must introduce the possibliity of this artificially. To do so, we will define some hyperparameter $\\eta$ to be the *probability* that we discard the original label $y$, and replace it with $\\varnothing$. In practice, we might set $\\varnothing = 10$, for example, as it is sufficient to distinguish it from the other digit identities. When we go and implement our model, we need ony be able to index into some embedding, such as via `torch.nn.Embedding`. We thus arrive at our CFG conditional flow matching training objective:\n",
    "$$\\mathcal{L}_{\\text{CFM}}(\\theta) = \\,\\,\\mathbb{E}_{z,y \\sim p_{\\text{data}}(z,y), x \\sim p_t(x|z),\\,\\xi \\sim \\mathcal{B}(\\eta) } \\lVert u_t^{\\theta}(x|y) - u_t^{\\text{ref}}(x|z,(1-\\xi)y + \\xi \\varnothing)\\rVert^2,$$\n",
    "where $\\mathcal{B}(\\eta)$ denotes the Bernoulli distribution with parameter $\\eta$, which evaluates to $1$ with probability $\\eta$ and zero otherwise. In plain English, this objective reads:\n",
    "1. Sample an image $z$ and a label $y$ from $p_{\\text{data}}$ (here, MNIST).\n",
    "2. Sample $\\xi \\sim \\text{Bernoulli}(\\eta)$. If $\\xi = 1$, replace the label $y$ with the null label $\\varnothing \\triangleq 10$. Otherwise, if $\\xi=0$, leave the label intact.\n",
    "3. Sample $t$ from $\\mathcal{U}[0,1]$.\n",
    "4. Sample $x$ from the conditional probability path $p_t(x|z)$.\n",
    "5. Regress $u_t^{\\theta}(x|y)$ against $u_t^{\\text{ref}}(x|z)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53545c1-0c24-482d-a9fc-2d3fa3f2d98a",
   "metadata": {},
   "source": [
    "### Question 2.2: Training for Classifier-Free Guidance\n",
    "In this section, you'll the training objective $\\mathcal{L}_{\\text{CFM}}(\\theta)$ in which $u_t^{\\theta}(x|y)$ is an instance of the class `ConditionalVectorField` described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb05534-12a5-49f6-b42a-15c5ac790041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalVectorField(nn.Module, ABC):\n",
    "    \"\"\"\n",
    "    MLP-parameterization of the learned vector field u_t^theta(x)\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, y: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, c, h, w)\n",
    "        - t: (bs, 1, 1, 1)\n",
    "        - y: (bs,)\n",
    "        Returns:\n",
    "        - u_t^theta(x|y): (bs, c, h, w)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class CFGVectorFieldODE(ODE):\n",
    "    def __init__(self, net: ConditionalVectorField, guidance_scale: float = 1.0):\n",
    "        self.net = net\n",
    "        self.guidance_scale = guidance_scale\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, c, h, w)\n",
    "        - t: (bs, 1, 1, 1)\n",
    "        - y: (bs,)\n",
    "        \"\"\"\n",
    "        guided_vector_field = self.net(x, t, y)\n",
    "        unguided_y = torch.ones_like(y) * 10\n",
    "        unguided_vector_field = self.net(x, t, unguided_y)\n",
    "        return (1 - self.guidance_scale) * unguided_vector_field + self.guidance_scale * guided_vector_field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ff57d-ab1f-47e8-a148-a1cf63bdc2af",
   "metadata": {},
   "source": [
    "**Your job (2 points)**: Fill in `CFGFlowTrainer.get_train_loss`, so that it implements $\\mathcal{L}_{\\text{CFM}}(\\theta)$ described above. In doing so, feel free to \"hardcode\" $\\varnothing = 10$. A more general implementation would not make this MNIST-specific assumption, but for the sake of this assignment you may do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cee73-d9ab-434e-aa28-6bd6e343983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGTrainer(Trainer):\n",
    "    def __init__(self, path: GaussianConditionalProbabilityPath, model: ConditionalVectorField, eta: float, **kwargs):\n",
    "        assert eta > 0 and eta < 1\n",
    "        super().__init__(model, **kwargs)\n",
    "        self.eta = eta\n",
    "        self.path = path\n",
    "\n",
    "    def get_train_loss(self, batch_size: int) -> torch.Tensor:\n",
    "        # Step 1: Sample z,y from p_data\n",
    "        z, y = self.path.p_data.sample(batch_size) # (bs, c, h, w), (bs,1)\n",
    "        \n",
    "        # Step 2: Set each label to 10 (i.e., null) with probability eta\n",
    "        xi = torch.rand(y.shape[0]).to(y.device)\n",
    "        y[xi > self.eta] = 10.0\n",
    "        \n",
    "        # Step 3: Sample t and x\n",
    "        t = torch.rand(batch_size,1,1,1).to(z) # (bs, 1, 1, 1)\n",
    "        x = self.path.sample_conditional_path(z,t) # (bs, 1, 32, 32)\n",
    "\n",
    "        # Step 4: Regress and output loss\n",
    "        ut_theta = self.model(x,t,y) # (bs, 1, 32, 32)\n",
    "        ut_ref = self.path.conditional_vector_field(x,z,t) # (bs, 1, 32, 32)\n",
    "        error = torch.einsum('bchw -> b', torch.square(ut_theta - ut_ref)) # (bs,)\n",
    "        return torch.mean(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca0376-dfb2-4ec9-ab0c-6f1943fdd191",
   "metadata": {},
   "source": [
    "# Part 3: An Architecture for Images\n",
    "At this point, we have discussed classifier free guidance, and the necessary considerations that must be made on the part of our model and in training our model. What remains is to actually discuss the choice of model. In particular, our usual choice of an MLP, while fine for the simple distributions of the previous lab, will no longer suffice. To this end, we will a new convolutional architecture - the **U-Net** - which is specifically tailored toward images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79bc767-5a66-4297-a54a-382dc26baecc",
   "metadata": {},
   "source": [
    "### Part 3.1: Building a U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3136b8-90cf-4417-80f5-2da083501459",
   "metadata": {},
   "source": [
    "TODO: INSERT DIAGRAM OF U-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3996e-81a7-427a-8c72-e3c6b0fafc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierEmbedder(nn.Module):\n",
    "    \"\"\"\n",
    "    Based on https://github.com/lucidrains/denoising-diffusion-pytorch/blob/main/denoising_diffusion_pytorch/karras_unet.py#L183\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0\n",
    "        self.half_dim = dim // 2\n",
    "        self.weights = nn.Parameter(torch.randn(1, self.half_dim))\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - t: (bs, 1, 1, 1)\n",
    "        Returns:\n",
    "        - embeddings: (bs, dim)\n",
    "        \"\"\"\n",
    "        t = t.view(-1, 1) # (bs, 1)\n",
    "        freqs = t * self.weights * 2 * math.pi # (bs, half_dim)\n",
    "        sin_embed = torch.sin(freqs) # (bs, half_dim)\n",
    "        cos_embed = torch.cos(freqs) # (bs, half_dim)\n",
    "        return torch.cat([sin_embed, cos_embed], dim=-1) * math.sqrt(2) # (bs, dim)\n",
    "    \n",
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, channels: int, time_embed_dim: int, y_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        # Converts (bs, time_embed_dim) -> (bs, channels)\n",
    "        self.time_adapter = nn.Sequential(\n",
    "            nn.Linear(time_embed_dim, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embed_dim, channels)\n",
    "        )\n",
    "        # Converts (bs, y_embed_dim) -> (bs, channels)\n",
    "        self.y_adapter = nn.Sequential(\n",
    "            nn.Linear(time_embed_dim, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embed_dim, channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor, y_embed: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, c, h, w)\n",
    "        - t_embed: (bs, t_embed_dim)\n",
    "        - y_embed: (bs, y_embed_dim)\n",
    "        \"\"\"\n",
    "        res = x.clone() # (bs, c, h, w)\n",
    "\n",
    "        # Initial conv block\n",
    "        x = self.block1(x) # (bs, c, h, w)\n",
    "\n",
    "        # Add time embedding\n",
    "        t_embed = self.time_adapter(t_embed).unsqueeze(-1).unsqueeze(-1) # (bs, c, 1, 1)\n",
    "        x = x + t_embed\n",
    "\n",
    "        # Add y embedding (conditional embedding)\n",
    "        y_embed = self.y_adapter(y_embed).unsqueeze(-1).unsqueeze(-1) # (bs, c, 1, 1)\n",
    "        x = x + y_embed\n",
    "\n",
    "        # Second conv block\n",
    "        x = self.block2(x) # (bs, c, h, w)\n",
    "\n",
    "        # Add back residual\n",
    "        x = x + res # (bs, c, h, w)\n",
    "\n",
    "        return x\n",
    "        \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels_in: int, channels_out: int, num_residual_layers: int, t_embed_dim: int, y_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            ResidualLayer(channels_in, t_embed_dim, y_embed_dim) for _ in range(num_residual_layers)\n",
    "        ])\n",
    "        self.downsample = nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor, y_embed: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, c_in, h, w)\n",
    "        - t_embed: (bs, t_embed_dim)\n",
    "        - y_embed: (bs, y_embed_dim)\n",
    "        \"\"\"\n",
    "        # Pass through residual blocks: (bs, c_in, h, w) -> (bs, c_in, h, w)\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x, t_embed, y_embed)\n",
    "\n",
    "        # Downsample: (bs, c_in, h, w) -> (bs, c_out, h // 2, w // 2)\n",
    "        x = self.downsample(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Midcoder(nn.Module):\n",
    "    def __init__(self, channels: int, num_residual_layers: int, t_embed_dim: int, y_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            ResidualLayer(channels, t_embed_dim, y_embed_dim) for _ in range(num_residual_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor, y_embed: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, c, h, w)\n",
    "        - t_embed: (bs, t_embed_dim)\n",
    "        - y_embed: (bs, y_embed_dim)\n",
    "        \"\"\"\n",
    "        # Pass through residual blocks: (bs, c, h, w) -> (bs, c, h, w)\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x, t_embed, y_embed)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels_in: int, channels_out: int, num_residual_layers: int, t_embed_dim: int, y_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear'), nn.Conv2d(channels_in, channels_out, kernel_size=3, padding=1))\n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            ResidualLayer(channels_out, t_embed_dim, y_embed_dim) for _ in range(num_residual_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor, y_embed: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, c, h, w)\n",
    "        - t_embed: (bs, t_embed_dim)\n",
    "        - y_embed: (bs, y_embed_dim)\n",
    "        \"\"\"\n",
    "        # Upsample: (bs, c_in, h, w) -> (bs, c_out, 2 * h, 2 * w) \n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # Pass through residual blocks: (bs, c_out, h, w) -> (bs, c_out, 2 * h, 2 * w)\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x, t_embed, y_embed)\n",
    "\n",
    "        return x\n",
    "        \n",
    "class MNISTUNet(ConditionalVectorField):\n",
    "    def __init__(self, channels: List[int], num_residual_layers: int, t_embed_dim: int, y_embed_dim: int): \n",
    "        super().__init__()\n",
    "        # Initial convolution: (bs, 1, 32, 32) -> (bs, c_0, 32, 32)\n",
    "        self.init_conv = nn.Sequential(nn.Conv2d(1, channels[0], kernel_size=3, padding=1), nn.BatchNorm2d(channels[0]), nn.SiLU())\n",
    "\n",
    "        # Initialize time embedder\n",
    "        self.time_embedder = FourierEmbedder(t_embed_dim)\n",
    "\n",
    "        # Initialize y embedder\n",
    "        self.y_embedder = nn.Embedding(num_embeddings = 11, embedding_dim = y_embed_dim)\n",
    "\n",
    "        # Encoders, Midcoders, and Decoders\n",
    "        encoders = []\n",
    "        decoders = []\n",
    "        for (curr_c, next_c) in zip(channels[:-1], channels[1:]):\n",
    "            encoders.append(Encoder(curr_c, next_c, num_residual_layers, t_embed_dim, y_embed_dim))\n",
    "            decoders.append(Decoder(next_c, curr_c, num_residual_layers, t_embed_dim, y_embed_dim))\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "        self.decoders = nn.ModuleList(reversed(decoders))\n",
    "\n",
    "        self.midcoder = Midcoder(channels[-1], num_residual_layers, t_embed_dim, y_embed_dim)\n",
    "            \n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(channels[0], 1, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, y: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, 1, 32, 32)\n",
    "        - t: (bs, 1, 1, 1)\n",
    "        - y: (bs,)\n",
    "        Returns:\n",
    "        - u_t^theta(x|y): (bs, 1, 32, 32)\n",
    "        \"\"\"\n",
    "        # Embed t and y\n",
    "        t_embed = self.time_embedder(t) # (bs, time_embed_dim)\n",
    "        y_embed = self.y_embedder(y) # (bs, y_embed_dim)\n",
    "        \n",
    "        # Initial convolution\n",
    "        x = self.init_conv(x) # (bs, c_0, 32, 32)\n",
    "\n",
    "        residuals = []\n",
    "        \n",
    "        # Encoders\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x, t_embed, y_embed) # (bs, c_i, h, w) -> (bs, c_{i+1}, h // 2, w //2)\n",
    "            residuals.append(x.clone())\n",
    "\n",
    "        # Midcoder\n",
    "        x = self.midcoder(x, t_embed, y_embed)\n",
    "\n",
    "        # Decoders\n",
    "        for decoder in self.decoders:\n",
    "            res = residuals.pop() # (bs, c_i, h, w)\n",
    "            x = x + res\n",
    "            x = decoder(x, t_embed, y_embed) # (bs, c_i, h, w) -> (bs, c_{i-1}, 2 * h, 2 * w)\n",
    "\n",
    "        # Final convolution\n",
    "        x = self.final_conv(x) # (bs, 1, 32, 32)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51937c-f010-4b45-ae9b-825fc31c8e46",
   "metadata": {},
   "source": [
    "### Question 3.2: Training a U-Net for Classifier-Free Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b61a28-dfa7-4d9c-83c3-45691b74c2a3",
   "metadata": {},
   "source": [
    "Now let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9503251-26a8-4340-9e3f-ad613b947a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize probability path\n",
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data = MNISTSampler(),\n",
    "    p_simple_shape = [1, 32, 32],\n",
    "    alpha = LinearAlpha(),\n",
    "    beta = LinearBeta()\n",
    ").to(device)\n",
    "\n",
    "# Initialize model\n",
    "unet = MNISTUNet(\n",
    "    channels = [32, 64, 128, 256],\n",
    "    num_residual_layers = 2,\n",
    "    t_embed_dim = 40,\n",
    "    y_embed_dim = 40,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = CFGTrainer(path = path, model = unet, eta=0.1)\n",
    "\n",
    "# Train!\n",
    "trainer.train(num_epochs = 10000, device=device, lr=1e-3, batch_size=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2260c7-49bb-4fdd-ab4b-4d064228d5af",
   "metadata": {},
   "source": [
    "How well does our model do? Let's find out! We'll use the class `CFGVectorFieldODE` to wrap the UNet in an instance of `ode` so that we can integrate it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce42792-36b0-4691-96a7-7a583b9ba503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with these!\n",
    "samples_per_class = 10\n",
    "num_timesteps = 100\n",
    "guidance_scales = [1.0, 3.0, 5.0]\n",
    "\n",
    "# Graph\n",
    "fig, axes = plt.subplots(1, len(guidance_scales), figsize=(10 * len(guidance_scales), 10))\n",
    "\n",
    "for idx, w in enumerate(guidance_scales):\n",
    "    # Setup ode and simulator\n",
    "    ode = CFGVectorFieldODE(unet, guidance_scale=w)\n",
    "    simulator = EulerSimulator(ode)\n",
    "\n",
    "    # Sample initial conditions\n",
    "    y = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=torch.int64).repeat_interleave(samples_per_class).to(device)\n",
    "    num_samples = y.shape[0]\n",
    "    x0, _ = path.p_simple.sample(num_samples) # (num_samples, 1, 32, 32)\n",
    "\n",
    "    # Simulate\n",
    "    ts = torch.linspace(0,1,num_timesteps).view(1, -1, 1, 1, 1).expand(num_samples, -1, 1, 1, 1).to(device)\n",
    "    x1 = simulator.simulate(x0, ts, y=y)\n",
    "\n",
    "    # Plot\n",
    "    grid = make_grid(x1, nrow=samples_per_class, normalize=True, value_range=(-1,1))\n",
    "    axes[idx].imshow(grid.permute(1, 2, 0).cpu(), cmap=\"gray\")\n",
    "    axes[idx].axis(\"off\")\n",
    "    axes[idx].set_title(f\"Guidance: $w={w:.1f}$\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e8109-296b-41b0-bd49-94a8647e2c71",
   "metadata": {},
   "source": [
    "**Your work (2 points):** What do you notice about our samples as the quality improves? Why might increasing the guidance scale $w$ have this affect? Propose an intuitive explanation in your own words.\n",
    "\n",
    "**Your answer**: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtds",
   "language": "python",
   "name": "mtds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
